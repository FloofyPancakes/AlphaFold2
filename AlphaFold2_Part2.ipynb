{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bbe9bd75-60ea-40cb-9897-cb938acf47a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as du\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "from torch.utils.data import Dataset\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sidechainnet as scn\n",
    "import random\n",
    "import sklearn\n",
    "import pytorch3d\n",
    "from pytorch3d import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "c9639572-518c-47ff-880f-52929b8139f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IPA(nn.Module):\n",
    "    '''\n",
    "    Invariant Point Attention\n",
    "    '''\n",
    "    def __init__(self, c_s = 384, c_z = 16, Nq=4, Nv=8, c=16, num_heads = 12):\n",
    "        super(IPA, self).__init__()\n",
    "        self.c = c\n",
    "        self.num_heads = num_heads\n",
    "        self.Nq = Nq\n",
    "        self.Nv = Nv\n",
    "        self.wl = np.sqrt(1/3)\n",
    "        self.wc = np.sqrt(2/(9*Nq))\n",
    "        \n",
    "        self.q = nn.ModuleList([nn.Linear(c_s, c, bias = False) for i in range(num_heads)])\n",
    "        self.k = nn.ModuleList([nn.Linear(c_s, c, bias = False) for i in range(num_heads)])\n",
    "        self.v = nn.ModuleList([nn.Linear(c_s, c, bias = False) for i in range(num_heads)])\n",
    "        self.qp = nn.ModuleList([nn.Linear(c_s, self.Nq*3, bias = False) for i in range(num_heads)])\n",
    "        self.kp = nn.ModuleList([nn.Linear(c_s, self.Nq*3, bias = False) for i in range(num_heads)])\n",
    "        self.vp = nn.ModuleList([nn.Linear(c_s, self.Nv*3, bias = False) for i in range(num_heads)])\n",
    "        self.b = nn.ModuleList([nn.Linear(c_z, 1, bias = False) for i in range(num_heads)])\n",
    "        self.gamma = nn.Parameter(torch.rand(num_heads))\n",
    "        self.fc1 = nn.Linear(num_heads * c_z, c_s)\n",
    "        self.fc2 = nn.Linear(num_heads * c_z, c_s)\n",
    "        self.fc3 = nn.Linear(num_heads * self.Nv*3, c_s)\n",
    "        \n",
    "    def forward(self, s, z, t):\n",
    "        o_hat_list = []\n",
    "        o_list = []\n",
    "        o_p_list = []\n",
    "        g = F.softplus(self.gamma)\n",
    "        for h in range(self.num_heads):\n",
    "            query = self.q[h](s).unsqueeze(dim=2)\n",
    "            key = self.k[h](s).unsqueeze(dim=2)\n",
    "            value = self.v[h](s).unsqueeze(dim=2)\n",
    "            query_p = self.qp[h](s)\n",
    "            key_p = self.kp[h](s)\n",
    "            value_p = self.vp[h](s)\n",
    "            query_p = torch.reshape(query_p, (query_p.shape[0], query_p.shape[1], self.Nq, 3)).unsqueeze(dim=2)     \n",
    "            key_p = torch.reshape(key_p, (key_p.shape[0], key_p.shape[1], self.Nq, 3)).unsqueeze(dim=2)\n",
    "            value_p = torch.reshape(value_p, (value_p.shape[0], value_p.shape[1], self.Nv, 3)).unsqueeze(dim=2)\n",
    "            bias = self.b[h](z)\n",
    "            a = 1/np.sqrt(self.c) * torch.einsum(\"bihc,bjhc->bijh\", query, key) + bias\n",
    "            ti = torch.einsum(\"bilm,bihpl->bihpm\", t[0], query_p) + t[1].unsqueeze(dim=2).unsqueeze(dim=2)\n",
    "            tj = torch.einsum(\"bjlm,bjhpl->bjhpm\", t[0], key_p) + t[1].unsqueeze(dim=2).unsqueeze(dim=2)\n",
    "            sqrt_diff = torch.norm(ti.unsqueeze(dim=2) - tj.unsqueeze(dim=1), dim=-1) ** 2\n",
    "            a -= g[h] * self.wc/2 * torch.sum(sqrt_diff, dim=-1)\n",
    "            a = F.softmax(self.wl * a, dim=2)\n",
    "            o_hat = torch.sum(torch.einsum(\"bmnh,booc->bmnhc\", a, z), dim=2)\n",
    "            o = torch.sum(torch.einsum(\"bmnh,bnhc->bmnhc\", a, value), dim=2)\n",
    "            t_v = torch.einsum(\"bjkl,bjhmk->bjhml\", t[0], value_p) + t[1].unsqueeze(dim=2).unsqueeze(dim=2)\n",
    "            a_t_v = torch.sum(torch.einsum(\"bijh,bjhpt->bijhpt\", a, t_v), dim=2)\n",
    "            o_p = torch.einsum(\"bmij,bmhpi->bmhpj\", torch.linalg.inv(t[0]), a_t_v) + t[1].unsqueeze(dim=2).unsqueeze(dim=2)\n",
    "            o_hat_list.append(o_hat)\n",
    "            o_list.append(o)\n",
    "            o_p_list.append(o_p)\n",
    "        o_hat_tensor = torch.concat(o_hat_list, 2)\n",
    "        o_tensor = torch.concat(o_list, 2)\n",
    "        o_p_tensor = torch.concat(o_p_list, 2)\n",
    "        o_hat_tensor = o_hat_tensor.reshape((o_hat_tensor.shape[0], o_hat_tensor.shape[1], o_hat_tensor.shape[2] * o_hat_tensor.shape[3]))\n",
    "        o_tensor = o_tensor.reshape((o_tensor.shape[0], o_tensor.shape[1], o_tensor.shape[2] * o_tensor.shape[3]))\n",
    "        o_p_tensor = o_p_tensor.reshape((o_p_tensor.shape[0], o_p_tensor.shape[1], o_p_tensor.shape[2] * o_p_tensor.shape[3] * o_p_tensor.shape[4]))\n",
    "        return (self.fc1(o_hat_tensor) + self.fc2(o_tensor) + self.fc3(o_p_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f672b3e8-9c48-4c44-a868-e0dc8ff7eedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BackUpdate(nn.Module):\n",
    "    '''\n",
    "    Given the single reprensation, returns a tuple of rotations and transitions.\n",
    "    '''\n",
    "    def __init__(self, c_s, device):\n",
    "        super(BackUpdate, self).__init__()\n",
    "        self.device = device\n",
    "        \n",
    "        #linear layer to project each row of the single rep\n",
    "        self.fc1 = nn.Linear(c_s,6)\n",
    "        \n",
    "    def forward(self, s):\n",
    "        #creates a list of rotations and transitions\n",
    "        list_r = torch.empty((s.shape[0], s.shape[1], 3, 3))\n",
    "        list_t = torch.empty((s.shape[0], s.shape[1], 3))\n",
    "        \n",
    "        for i in range(s.shape[1]):\n",
    "            proj = self.fc1(s[:,i,:])\n",
    "            \n",
    "            #obtain b,c,d quaternion and the transition t\n",
    "            b = proj[:,0]\n",
    "            c = proj[:,1]\n",
    "            d = proj[:,2]\n",
    "            a = torch.ones(b.shape)\n",
    "            t = proj[:,3:]\n",
    "            \n",
    "            #compute the quaternion\n",
    "            a, b, c, d = torch.unsqueeze(a, dim = 0), torch.unsqueeze(b, dim = 0), torch.unsqueeze(c, dim = 0), torch.unsqueeze(d, dim = 0)\n",
    "            total = torch.concat((a,b,c,d), dim = 0)\n",
    "            \n",
    "            #batch x normalized quaternion \n",
    "            q = F.normalize(total, dim = 0)\n",
    "            \n",
    "            #convert the quaternion into a rotation matrix\n",
    "            r = pytorch3d.transforms.quaternion_to_matrix(q)\n",
    "            \n",
    "            list_r[:,i,:,:] = r\n",
    "            list_t[:,i,:] = t\n",
    "        #returns a tuple of all predicted rotations(b x n_res x 3 x3)\n",
    "        #and transitions (b x n_res x 3)\n",
    "        return (list_r, list_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "8c1026dc-c22b-4755-ab63-cee85a317fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PredictAngleTorsion(nn.Module):\n",
    "    '''\n",
    "    Given the updated single representation and single representation,\n",
    "    predicts phi and psi angles.\n",
    "    '''\n",
    "    def __init__(self, c_s, device):\n",
    "        super(PredictAngleTorsion, self).__init__()\n",
    "        self.device = device\n",
    "        \n",
    "        #project s to 128\n",
    "        self.fc1 = nn.Linear(c_s, 128)\n",
    "        #project s_i to 128\n",
    "        self.fc2 = nn.Linear(c_s, 128)\n",
    "        \n",
    "        #projects a from 128 to ?\n",
    "        self.layers1 = nn.Sequential(nn.Linear(128,128), nn.ReLU(), nn.Linear(128,128), nn.ReLU())\n",
    "        self.layers2 = nn.Sequential(nn.Linear(128,128), nn.ReLU(), nn.Linear(128,128), nn.ReLU())\n",
    "        \n",
    "        #projects a into phi and psi\n",
    "        self.phi = nn.Sequential(nn.Linear(128, 2), nn.ReLU())\n",
    "        self.psi = nn.Sequential(nn.Linear(128, 2), nn.ReLU())\n",
    "        \n",
    "    def forward(self, s, s_i):\n",
    "        proj_s = self.fc1(s)\n",
    "        proj_si = self.fc2(s_i)\n",
    "        \n",
    "        a_i = proj_s + proj_si\n",
    "        a_i = self.layers1(a_i) + a_i\n",
    "        a_i = self.layers2(a_i) + a_i\n",
    "        \n",
    "        phi = self.phi(a_i)\n",
    "        psi = self.psi(a_i)\n",
    "        \n",
    "        return phi, psi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "3b71bda5-8f79-4af2-8117-ddd5d2d2c641",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FAPE(nn.Module):\n",
    "    '''\n",
    "    Calculates Frame Aligned Point Error Loss.\n",
    "    '''\n",
    "    def __init__(self, device):\n",
    "        super(FAPE, self).__init__()\n",
    "        self.device = device\n",
    "    \n",
    "    def forward(self, T_pred, x_pred, T_true, x_true):\n",
    "        p_rot = T_pred[0]\n",
    "        p_trans = T_pred[1]\n",
    "        t_rot = T_true[0]\n",
    "        t_trans = T_true[1]\n",
    "        \n",
    "        all_dist = []\n",
    "        #for all frames, align then true and predicted frames\n",
    "        for i in range(p_rot.shape[1]):\n",
    "            p_inv = torch.linalg.inv(p_rot[:,i,:,:])\n",
    "            t_inv = torch.linalg.inv(t_rot[:,i,:,:])\n",
    "            aligned_xp = torch.matmul(x_pred, p_rot[:,i,:,:])\n",
    "            aligned_xt = torch.matmul(x_true, t_rot[:,i,:,:])\n",
    "            #for all j, compute distances.\n",
    "            for j in range(aligned_xp.shape[1]):\n",
    "                dist = torch.linalg.norm(aligned_xp[:,j,:] - aligned_xt[:,j,:], dim = 1)\n",
    "                eps = torch.ones(dist.shape)*(0.0001)\n",
    "                dist = torch.sqrt(torch.square(dist) + eps)\n",
    "                all_dist.append(dist)\n",
    "        \n",
    "        #concat all bx1 tensors and obtain a single mean loss value.\n",
    "        all_dist = torch.concat(all_dist, dim = -1)\n",
    "        f_loss = torch.mean(all_dist)/10\n",
    "        \n",
    "        return f_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "d2f0ab67-e59f-4f0a-9a9b-44d37ed2c353",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AngleTorsionLoss(nn.Module):\n",
    "    '''\n",
    "    Computes angular torsion loss given predicted angles and true angles psi and phi.\n",
    "    '''\n",
    "    def __init__(self):\n",
    "        super(AngleTorsionLoss, self).__init__()\n",
    "    \n",
    "    def forward(self, p_psi, p_phi, t_psi, t_phi):\n",
    "        norms = []\n",
    "        dists = []\n",
    "        #iterate through all angles and calculate angle norm and distance.\n",
    "        for i in range(p_psi.shape[1]):\n",
    "            #calculate angle norms for psi and phi\n",
    "            l_psi = torch.norm(p_psi[:,i,:], dim = 1)\n",
    "            l_phi = torch.norm(p_phi[:,i,:], dim = 1)\n",
    "            \n",
    "            lt_psi = torch.tile(l_psi.unsqueeze(dim = -1), (1, 2))\n",
    "            lt_phi = torch.tile(l_phi.unsqueeze(dim = -1), (1, 2))\n",
    "            \n",
    "            #make unit vectors for psi and phi, WILL GET NANS WHEN li_psi has 0s. The model should not be predicting 0,0 for angles as it is not a valid angle.\n",
    "            u_psi = torch.div(p_psi[:,i,:],lt_psi)\n",
    "            u_phi = torch.div(p_phi[:,i,:],lt_phi)\n",
    "            \n",
    "            #calculate distance between prediction and true values\n",
    "            dist_psi = torch.square(torch.linalg.norm(u_psi - t_psi[:,i,:]))\n",
    "            dist_phi = torch.square(torch.linalg.norm(u_phi - t_phi[:,i,:]))\n",
    "            \n",
    "            #append angle norm and distance to their respective lists\n",
    "            norms.append(abs(l_psi-1))\n",
    "            norms.append(abs(l_phi-1))\n",
    "            dists.append(dist_psi)\n",
    "            dists.append(dist_phi)\n",
    "        \n",
    "        #concatenate all norms and all dists and find respective means.\n",
    "        all_norms = torch.mean(torch.stack(norms, dim = 0))\n",
    "        all_dists = torch.mean(torch.stack(dists, dim = 0))\n",
    "        \n",
    "        #calculate loss\n",
    "        torsion_angular_loss = all_norms + all_dists\n",
    "        \n",
    "        return torsion_angular_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "4f973c58-b3ce-46b5-abf1-aa5d2ddab1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StructureModel(nn.Module):\n",
    "    '''\n",
    "    Predicts 3D protein structure coordinate.\n",
    "    '''\n",
    "    def __init__(self, c_s, layers, device):\n",
    "        super(StructureModel, self).__init__()\n",
    "        self.layers = layers\n",
    "        self.device = device\n",
    "        \n",
    "        #Define a layer in structure prediction.\n",
    "        self.transition = nn.Sequential(nn.Linear(c_s, c_s), nn.ReLU(), nn.Linear(c_s, c_s), nn.ReLU(), nn.Linear(c_s, c_s))\n",
    "        self.ipa = IPA(c_s)\n",
    "        self.update_b = BackUpdate(c_s, device)\n",
    "        self.torsion = PredictAngleTorsion(c_s, device)\n",
    "        self.fape = FAPE(device)\n",
    "        self.t_loss = AngleTorsionLoss()\n",
    "        \n",
    "    def forward(self, s_i, pair_rep):\n",
    "        #Initialize a reference frame T\n",
    "        identity = iden = torch.tile(torch.eye(3).unsqueeze(dim=0).unsqueeze(dim=0), (s_i.shape[0], s_i.shape[1], 1, 1))\n",
    "        translation = torch.zeros(s_i.shape[0], s_i.shape[1], 3)\n",
    "        t_i = (identity, translation)\n",
    "        \n",
    "        #store all calculated losses\n",
    "        total_l_aux = []\n",
    "        for layer in range(self.layers):\n",
    "            s = self.ipa(s_i, pair_rep, t_i) + s_i\n",
    "            s = self.transition(s) + s\n",
    "\n",
    "            t_new = self.update_b(s)\n",
    "            \n",
    "            #multiply all respective rotation matricies, add all respective transitions\n",
    "            new_trans = t_new[1] + t_i[1]\n",
    "            new_rot = torch.matmul(t_new[0], t_i[0])\n",
    "            \n",
    "            #update t_i\n",
    "            t_i = (new_rot, new_trans)\n",
    "                \n",
    "            #the predicted x is just the transition\n",
    "            x_pred = t_i[1]\n",
    "            \n",
    "            #predict phi psi angles\n",
    "            p_phi, p_psi = self.torsion(s, s_i)\n",
    "            \n",
    "            #calculate loss\n",
    "            fape_loss = self.fape(t_i, x_pred, t_true, x_true)\n",
    "            torsion_loss = self.t_loss(p_psi, p_phi, t_psi, t_phi)\n",
    "            loss_aux = fape_loss + torsion_loss\n",
    "            \n",
    "            total_l_aux.append(loss_aux)\n",
    "        mean_loss_aux = torch.mean(torch.stack(loss_aux, dim = 0))\n",
    "        return mean_loss_aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "9f5956fb-f39f-4d58-bafa-6af0deab9232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cpu\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 't_true' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_7642/170523234.py\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#create test model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mstruct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStructureModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m384\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_s_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpair_rep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_7642/4014060127.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, s_i, pair_rep)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;31m#calculate loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0mfape_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_i\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m             \u001b[0mtorsion_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp_psi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_phi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_psi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_phi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mloss_aux\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfape_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorsion_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 't_true' is not defined"
     ]
    }
   ],
   "source": [
    "device = f'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"using device: {device}\")\n",
    "\n",
    "#Generate test tensors\n",
    "t_s_i = torch.rand(4, 64, 384)\n",
    "pair_rep = torch.rand(4, 64, 64, 16)\n",
    "\n",
    "#create test model\n",
    "struct = StructureModel(384, 1, device)\n",
    "out = struct(t_s_i, pair_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1902ce39-9a47-4840-a6b1-8045d91b0807",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e30c0e5a-393a-4b54-8e88-83b0bbca0842",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62dd83e-61a1-46a9-83c9-1e9b2e2d49bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
