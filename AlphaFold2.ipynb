{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eedec855-48c9-47df-9a96-c99b6e62656f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as du\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sidechainnet as scn\n",
    "import random\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80adece-2499-45bb-9275-0632cbdaf960",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = scn.load(casp_version=7, with_pytorch=\"dataloaders\", \n",
    "                seq_as_onehot=True, aggregate_model_input=False,\n",
    "               batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94d25bc-a054-46b4-bbb3-c7a5945394ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seq_features(batch):\n",
    "    '''\n",
    "    Take a batch of sequence info and return the sequence (one-hot),\n",
    "    evolutionary info and (phi, psi, omega) angles per position, \n",
    "    as well as position mask.\n",
    "    Also return the distance matrix, and distance mask.\n",
    "    '''\n",
    "    str_seqs = batch.str_seqs # seq in str format\n",
    "    seqs = batch.seqs # seq in one-hot format\n",
    "    int_seqs = batch.int_seqs # seq in int format\n",
    "    masks = batch.msks # which positions are valid\n",
    "    lengths = batch.lengths # seq length\n",
    "    evos = batch.evos # PSSM / evolutionary info\n",
    "    angs = batch.angs[:,:,0:2] # torsion angles: phi, psi\n",
    "    \n",
    "    # use coords to create distance matrix from c-beta\n",
    "    # except use c-alpha for G\n",
    "    # coords[:, 4, :] is c-beta, and coords[:, 1, :] is c-alpha\n",
    "    coords = batch.crds # seq coord info (all-atom)\n",
    "    batch_xyz = []\n",
    "    for i in range(coords.shape[0]):\n",
    "        xyz = []\n",
    "        xyz = [coords[i][cpos+4,:] \n",
    "                if masks[i][cpos//14] and str_seqs[i][cpos//14] != 'G'\n",
    "                else coords[i][cpos+1,:]\n",
    "                for cpos in range(0, coords[i].shape[0]-1, 14)]\n",
    "        batch_xyz.append(torch.stack(xyz))\n",
    "    batch_xyz = torch.stack(batch_xyz)\n",
    "    # now create pairwise distance matrix\n",
    "    dmats = torch.cdist(batch_xyz, batch_xyz)\n",
    "    # create matrix mask (0 means i,j invalid)\n",
    "    dmat_masks = torch.einsum('bi,bj->bij', masks, masks)\n",
    "    \n",
    "    return seqs, evos, angs, masks, dmats, dmat_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a78894-7d51-4726-99b0-521cec455498",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1,epochs+1):\n",
    "    for batch in data['train']:\n",
    "        seqs, evos, angs, masks, dmats, dmat_masks = get_seq_features(batch)\n",
    "        seqs, evos, angs, masks, dmats, dmat_masks = seqs.to(device), evos.to(device), angs.to(device), masks.to(device), dmats.to(device), dmat_masks.to(device)\n",
    "        \n",
    "        print(seqs.shape, evos.shape, angs.shape)\n",
    "        print(masks.shape, dmats.shape, dmat_mask.shape)\n",
    "        \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6969eac3-0163-479e-bc59-ae546aa2d338",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionHead(nn.Module):\n",
    "    def __init__(self, in_dim = 256, d_k = 32):\n",
    "        '''\n",
    "        Represents an attention head for multihead attention,\n",
    "        d_k is 32 by default.\n",
    "        in_dim is 256 by default.\n",
    "        '''\n",
    "        super(AttentionHead, self).__init__()\n",
    "        \n",
    "        self.d_k = d_k\n",
    "        #create query, key, and values\n",
    "        self.q = nn.Linear(in_dim, d_k)\n",
    "        self.k = nn.Linear(in_dim, d_k)\n",
    "        self.v = nn.Linear(in_dim, d_k)\n",
    "        \n",
    "    def forward(self, sequence, bias, row_or_col):\n",
    "        '''\n",
    "        Given a sequence in MSA_rep of size n_res x 256, calculate attention.\n",
    "        Depending on row_or_col, bias is either added or excluded.\n",
    "        '''\n",
    "        query = self.q(sequence)\n",
    "        key = self.k(sequence)\n",
    "        value = self.v(sequence)\n",
    "        \n",
    "        A_sh = torch.matmul(query, torch.transpose(key, 1, 2)) / torch.sqrt(self.d_k)\n",
    "        \n",
    "        if row_or_col == \"row\":\n",
    "            A_sh += bias\n",
    "        \n",
    "        #take softmax with respect to the rows\n",
    "        A_sh = F.softmax(A_sh, dim = 0)\n",
    "        A_sh = torch.matmul(A_sh, value)\n",
    "        \n",
    "        return A_sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df0f741-c8fc-4e5e-858b-6a635e630516",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evoformer(nn.Module):\n",
    "    def __init__(self, n_clust, num_heads = 8):\n",
    "        '''\n",
    "        Creates the MSA_representation and the Z(pairwise) matrix given a PSSM and a sequence.\n",
    "        n_clust: number of PSSMs.\n",
    "        num_heads: number of attention heads(8 by default)\n",
    "        '''\n",
    "        super(Evoformer, self).__init__()\n",
    "        \n",
    "        self.n_clust = n_clust\n",
    "        self.num_heads = num_heads\n",
    "        \n",
    "        #linear layer to project evos into n_clust x n_res x 256\n",
    "        self.fc0 = nn.Linear(21, 256)\n",
    "        #linear layer to project targets to n_res x 256\n",
    "        self.fc1 = nn.Linear(21, 256)\n",
    "        #linear layer to project target to n_res x 128\n",
    "        self.fc2 = nn.Linear(21, 128)\n",
    "        #Linear layer to project distances into 128 space\n",
    "        self.fc3 = nn.Linear(21, 128)\n",
    "        #linear layer to project pair_rep to bias\n",
    "        self.fc4 = nn.Linear(128, 1)\n",
    "        #linear layer to project the new msa_rep into 256 dim\n",
    "        self.fc5 = nn.Linear(32, 256)\n",
    "        #linear layer to project i[s] and j[s] to 32 dim\n",
    "        self.fc6 = nn.Linear(256, 32)\n",
    "        #flatten the mean outer product to C*C\n",
    "        self.flatten = nn.Flatten()\n",
    "        #linear layer to project the outer product mean to 128 dim\n",
    "        self.fc7 = nn.Linear(32, 128)\n",
    "        \n",
    "        #define attention heads\n",
    "        self.mha = nn.ModuleList([AttentionHead() for i in range(num_heads)])\n",
    "        \n",
    "        #create a gate for each head, corresponding to each index.\n",
    "        #a gate maps msa_rep to 1 and sigmoids it to determine how much information is kept from a head.\n",
    "        self.gates = nn.ModuleList[nn.Sequential(nn.Linear(256, 1), nn.Sigmoid()) for i in range(num_heads)]\n",
    "        \n",
    "        #define the transitional layers to pass the new msa_rep through\n",
    "        self.transition = nn.Sequential(nn.Linear(256, 1024), F.relu(), nn.Linear(1024, 256))\n",
    "    \n",
    "    def create_msa_rep(self, evos, target):\n",
    "        '''\n",
    "        Create the msa_representation given evolutionary data evos\n",
    "        and the targets, both are n_res x 21.\n",
    "        '''\n",
    "        #obtain n_clust layers of PSSM(evos); stack them into a (n_clust x n_res x 256) matrix\n",
    "        clusters = [self.fc0(evos) for i in range(self.n_clust)]\n",
    "        msa_rep = torch.vstack(clusters)\n",
    "        \n",
    "        #project the targets from n_res x 21 to n_res x 256 and tile it.\n",
    "        new_target = self.fc1(target)\n",
    "        new_target = torch.tile(target, (1, 1, self.n_clust))\n",
    "        \n",
    "        #add the targets to the msa_rep\n",
    "        msa_rep += new_target\n",
    "        \n",
    "        return msa_rep\n",
    "    \n",
    "    def create_pair_rep(self, target):\n",
    "        '''\n",
    "        Create pair_wise representations given targets.\n",
    "        '''\n",
    "        #create the pairwise rep matrix\n",
    "        a_i = self.fc2(target)\n",
    "        b_j = self.fc2(target)\n",
    "        pair_rep = torch.outer(a_i, b_j)\n",
    "        \n",
    "        #add the relative position rel_pos\n",
    "        idx_j = torch.arange(0, dmats.shape[1])\n",
    "        idx_j = torch.tile(idx_j, (idx_i.shape[1], 1))\n",
    "        idx_i = torch.transpose(idx_j, 0, 1)\n",
    "        idx_i , idx_j = idx_i.to(device), idx_j.to(device)\n",
    "        dist_ij = idx_i - idx_j   \n",
    "        bins = torch.linspace(-32, 32, 64)\n",
    "        dist_ij = torch.bucketize(dist_ij, bins)\n",
    "        rel_pos = self.fc3(F.one_hot(dist_ij))\n",
    "        \n",
    "        pair_rep += rel_pos\n",
    "        return pair_rep\n",
    "    \n",
    "    def create_bias(self, pair_rep):\n",
    "        '''\n",
    "        given the pairwise representation create the bias\n",
    "        '''\n",
    "        bias = self.fc4(pair_rep)\n",
    "        return bias\n",
    "        \n",
    "    def compute_attention(self, row_or_col, msa_rep, bias):\n",
    "        '''\n",
    "        compute either row-wise or column-wise attention depending on the given argument.\n",
    "        '''\n",
    "        t_msa_rep = msa_rep\n",
    "        if row_or_col == \"col\":\n",
    "            #transpose the msa_rep if we are doing column wise attention\n",
    "            t_msa_rep = torch.transpose(t_msa_rep, 0, 1)\n",
    "        \n",
    "        #calculate all the respective gates dot attention head outputs.\n",
    "        outputs = [torch.dot(self.mha[i](msa_rep[s], bias, row_or_col), self.gates[i](msa_rep))\n",
    "                   for s in range(msa_rep.shape[0]) for i in range(self.num_heads)]\n",
    "        \n",
    "        #concatenate them to form O_sh\n",
    "        O_sh = torch.concat(outputs, dim = 2)\n",
    "        new_msa_rep = self.fc5(O_sh)\n",
    "        \n",
    "        return new_msa_rep\n",
    "    \n",
    "    def outer_product_mean(self, msa_rep):\n",
    "        '''\n",
    "        Finds the outer product mean between the pair-wise representation\n",
    "        and the msa representation.\n",
    "        The output is a n_res x n_res x 128 pair_rep\n",
    "        '''\n",
    "        #iterate through clusters, pick slices i and j and project them into 32 dim and gather their outer products\n",
    "        for i in range(msa_rep.shape[1]):\n",
    "            outer_prods = [torch.outer(self.fc6(msa_rep[i][s]), self.fc6(msa_rep[j][s]))\n",
    "                           for j in range(msa_rep.shape[1]) for s in range(msa_rep.shape[0])]\n",
    "        \n",
    "        #concatenate all o_ij to make the output and take the mean\n",
    "        new_pair_rep = torch.mean(torch.concat(outer_prods, dim = 2))\n",
    "        new_pair_rep = self.flatten(new_pair_rep)\n",
    "        \n",
    "        #project to n_res x n_res x 128 dim\n",
    "        new_pair_rep = self.fc7(new_pair_rep)\n",
    "        \n",
    "        #make sure to do residual connection after calling the function\n",
    "        return new_pair_rep\n",
    "        \n",
    "    def mult_attention(self, out = False):\n",
    "        '''\n",
    "        Does incoming(default) multiplicative attention on a given pair_rep.\n",
    "        out: set to true to do outgoing attention\n",
    "        '''\n",
    "        \n",
    "        \n",
    "    def tri_attention(self, ending = False):\n",
    "        '''\n",
    "        Does starting triangular attention by default.\n",
    "        ending: set to true to do ending triangular attention\n",
    "        '''\n",
    "        \n",
    "    def single_rep(self):\n",
    "        '''\n",
    "        Find the singular representation of M\n",
    "        Should only be done on the last block.\n",
    "        '''\n",
    "    \n",
    "    \n",
    "    def forward(self, seqs, evos, dmats):\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b987615-c87a-4fa2-90de-d353648535cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: In the end divide evoformer into separate models so that the code becomes more clear"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
