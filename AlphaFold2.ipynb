{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eedec855-48c9-47df-9a96-c99b6e62656f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as du\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sidechainnet as scn\n",
    "import random\n",
    "import sklearn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80adece-2499-45bb-9275-0632cbdaf960",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = scn.load(casp_version=7, with_pytorch=\"dataloaders\", \n",
    "                seq_as_onehot=True, aggregate_model_input=False,\n",
    "               batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94d25bc-a054-46b4-bbb3-c7a5945394ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seq_features(batch):\n",
    "    '''\n",
    "    Take a batch of sequence info and return the sequence (one-hot),\n",
    "    evolutionary info and (phi, psi, omega) angles per position, \n",
    "    as well as position mask.\n",
    "    Also return the distance matrix, and distance mask.\n",
    "    '''\n",
    "    str_seqs = batch.str_seqs # seq in str format\n",
    "    seqs = batch.seqs # seq in one-hot format\n",
    "    int_seqs = batch.int_seqs # seq in int format\n",
    "    masks = batch.msks # which positions are valid\n",
    "    lengths = batch.lengths # seq length\n",
    "    evos = batch.evos # PSSM / evolutionary info\n",
    "    angs = batch.angs[:,:,0:2] # torsion angles: phi, psi\n",
    "    \n",
    "    # use coords to create distance matrix from c-beta\n",
    "    # except use c-alpha for G\n",
    "    # coords[:, 4, :] is c-beta, and coords[:, 1, :] is c-alpha\n",
    "    coords = batch.crds # seq coord info (all-atom)\n",
    "    batch_xyz = []\n",
    "    for i in range(coords.shape[0]):\n",
    "        xyz = []\n",
    "        xyz = [coords[i][cpos+4,:] \n",
    "                if masks[i][cpos//14] and str_seqs[i][cpos//14] != 'G'\n",
    "                else coords[i][cpos+1,:]\n",
    "                for cpos in range(0, coords[i].shape[0]-1, 14)]\n",
    "        batch_xyz.append(torch.stack(xyz))\n",
    "    batch_xyz = torch.stack(batch_xyz)\n",
    "    # now create pairwise distance matrix\n",
    "    dmats = torch.cdist(batch_xyz, batch_xyz)\n",
    "    # create matrix mask (0 means i,j invalid)\n",
    "    dmat_masks = torch.einsum('bi,bj->bij', masks, masks)\n",
    "    \n",
    "    return seqs, evos, angs, masks, dmats, dmat_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a78894-7d51-4726-99b0-521cec455498",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1,epochs+1):\n",
    "    for batch in data['train']:\n",
    "        seqs, evos, angs, masks, dmats, dmat_masks = get_seq_features(batch)\n",
    "        seqs, evos, angs, masks, dmats, dmat_masks = seqs.to(device), evos.to(device), angs.to(device), masks.to(device), dmats.to(device), dmat_masks.to(device)\n",
    "        \n",
    "        print(seqs.shape, evos.shape, angs.shape)\n",
    "        print(masks.shape, dmats.shape, dmat_mask.shape)\n",
    "        \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6969eac3-0163-479e-bc59-ae546aa2d338",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionHead(nn.Module):\n",
    "    def __init__(self, in_dim = 256, d_k = 32):\n",
    "        '''\n",
    "        Represents an attention head for multihead attention,\n",
    "        d_k is 32 by default.\n",
    "        in_dim is 256 by default.\n",
    "        '''\n",
    "        super(AttentionHead, self).__init__()\n",
    "        \n",
    "        self.d_k = d_k\n",
    "        #create query, key, and values\n",
    "        self.q = nn.Linear(in_dim, d_k)\n",
    "        self.k = nn.Linear(in_dim, d_k)\n",
    "        self.v = nn.Linear(in_dim, d_k)\n",
    "        \n",
    "    def forward(self, sequence, bias, row_or_col):\n",
    "        '''\n",
    "        Given a sequence in MSA_rep of size n_res x 256, calculate attention.\n",
    "        Depending on row_or_col, bias is either added or excluded.\n",
    "        '''\n",
    "        query = self.q(sequence)\n",
    "        key = self.k(sequence)\n",
    "        value = self.v(sequence)\n",
    "        \n",
    "        A_sh = torch.matmul(query, torch.transpose(key, 1, 2)) / torch.sqrt(self.d_k)\n",
    "        \n",
    "        if row_or_col == \"row\":\n",
    "            A_sh += bias\n",
    "        \n",
    "        #take softmax with respect to the rows\n",
    "        A_sh = F.softmax(A_sh, dim = 0)\n",
    "        A_sh = torch.matmul(A_sh, value)\n",
    "        \n",
    "        return A_sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df0f741-c8fc-4e5e-858b-6a635e630516",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evoformer(nn.Module):\n",
    "    def __init__(self, n_clust, num_heads = 8):\n",
    "        '''\n",
    "        Creates the MSA_representation and the Z(pairwise) matrix given a PSSM and a sequence.\n",
    "        n_clust: number of PSSMs.\n",
    "        num_heads: number of attention heads(8 by default)\n",
    "        '''\n",
    "        super(Evoformer, self).__init__()\n",
    "        \n",
    "        self.n_clust = n_clust\n",
    "        self.num_heads = num_heads\n",
    "        \n",
    "        #linear layer to project evos into n_clust x n_res x 256\n",
    "        self.fc0 = nn.Linear(21, 256)\n",
    "        #linear layer to project targets to n_res x 256\n",
    "        self.fc1 = nn.Linear(21, 256)\n",
    "        #linear layer to project target to n_res x 128\n",
    "        self.fc2 = nn.Linear(21, 128)\n",
    "        #Linear layer to project distances into 128 space\n",
    "        self.fc3 = nn.Linear(21, 128)\n",
    "        #linear layer to project pair_rep to bias\n",
    "        self.fc4 = nn.Linear(128, 1)\n",
    "        #linear layer to project the new msa_rep into 256 dim\n",
    "        self.fc5 = nn.Linear(32, 256)\n",
    "        \n",
    "        #define attention heads\n",
    "        self.mha = nn.ModuleList([AttentionHead() for i in range(num_heads)])\n",
    "        \n",
    "        #create a gate for each head, corresponding to each index.\n",
    "        #a gate maps msa_rep to 1 and sigmoids it to determine how much information is kept from a head.\n",
    "        self.gates = nn.ModuleList[nn.Sequential(nn.Linear(256, 1), nn.Sigmoid()) for i in range(num_heads)]\n",
    "        \n",
    "        #define the transitional layers to pass the new msa_rep through\n",
    "        self.transition = nn.Sequential(nn.Linear(256, 1024), F.relu(), nn.Linear(1024, 256))\n",
    "    \n",
    "    def create_msa_rep(self, evos, target):\n",
    "        '''\n",
    "        Create the msa_representation given evolutionary data evos\n",
    "        and the targets, both are n_res x 21.\n",
    "        '''\n",
    "        #obtain n_clust layers of PSSM(evos); stack them into a (n_clust x n_res x 256) matrix\n",
    "        clusters = [self.fc0(evos) for i in range(self.n_clust)]\n",
    "        msa_rep = torch.vstack(clusters)\n",
    "        \n",
    "        #project the targets from n_res x 21 to n_res x 256 and tile it.\n",
    "        new_target = self.fc1(target)\n",
    "        new_target = torch.tile(target, (1, 1, self.n_clust))\n",
    "        \n",
    "        #add the targets to the msa_rep\n",
    "        msa_rep += new_target\n",
    "        \n",
    "        return msa_rep\n",
    "    \n",
    "    def create_pair_rep(self, target, dmats, device):\n",
    "        '''\n",
    "        Create pair_wise representations given targets.\n",
    "        '''\n",
    "        #create the pairwise rep matrix\n",
    "        a_i = self.fc2(target)\n",
    "        b_j = self.fc2(target)\n",
    "        pair_rep = torch.outer(a_i, b_j)\n",
    "        \n",
    "        #add the relative position rel_pos\n",
    "\n",
    "        idx_j = torch.arange(0, dmats.shape[1])\n",
    "        idx_j = torch.tile(idx_j, (idx_i.shape[1], 1))\n",
    "        idx_i = torch.transpose(idx_j, 0, 1)\n",
    "        idx_i , idx_j = idx_i.to(device), idx_j.to(device)\n",
    "        dist_ij = idx_i - idx_j   \n",
    "\n",
    "        bins = torch.arange(-32, 32, 1)\n",
    "        dist_ij = torch.bucketize(dist_ij, bins)\n",
    "        rel_pos = self.fc3(F.one_hot(dist_ij))\n",
    "        \n",
    "        pair_rep += rel_pos\n",
    "        return pair_rep\n",
    "    \n",
    "    def create_bias(self, pair_rep):\n",
    "        '''\n",
    "        given the pairwise representation create the bias\n",
    "        '''\n",
    "        bias = self.fc4(pair_rep)\n",
    "        return bias\n",
    "        \n",
    "    def compute_attention(self, row_or_col, msa_rep, bias):\n",
    "        '''\n",
    "        compute either row-wise or column-wise attention depending on the given argument.\n",
    "        '''\n",
    "        t_msa_rep = msa_rep\n",
    "        if row_or_col == \"col\":\n",
    "            #transpose the msa_rep if we are doing column wise attention\n",
    "            t_msa_rep = torch.transpose(t_msa_rep, 0, 1)\n",
    "        \n",
    "        #calculate all the respective gates dot attention head outputs.\n",
    "        outputs = [torch.dot(self.mha[i](msa_rep[s], bias, row_or_col), self.gates[i](msa_rep))\n",
    "                   for s in range(msa_rep.shape[0]) for i in range(self.num_heads)]\n",
    "        \n",
    "        #concatenate them to form O_sh\n",
    "        O_sh = torch.concat(outputs, dim = 2)\n",
    "        new_msa_rep = self.fc5(O_sh)\n",
    "        \n",
    "        return new_msa_rep\n",
    "    \n",
    "    def forward(self):\n",
    "        return"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "conda-env-default-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
