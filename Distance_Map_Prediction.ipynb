{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eedec855-48c9-47df-9a96-c99b6e62656f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as du\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sidechainnet as scn\n",
    "import random\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a80adece-2499-45bb-9275-0632cbdaf960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SidechainNet was loaded from ./sidechainnet_data/sidechainnet_casp7_30.pkl.\n"
     ]
    }
   ],
   "source": [
    "data = scn.load(casp_version=7, with_pytorch=\"dataloaders\", \n",
    "                seq_as_onehot=True, aggregate_model_input=False,\n",
    "               batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b94d25bc-a054-46b4-bbb3-c7a5945394ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seq_features(batch):\n",
    "    '''\n",
    "    Take a batch of sequence info and return the sequence (one-hot),\n",
    "    evolutionary info and (phi, psi, omega) angles per position, \n",
    "    as well as position mask.\n",
    "    Also return the distance matrix, and distance mask.\n",
    "    '''\n",
    "    str_seqs = batch.str_seqs # seq in str format\n",
    "    seqs = batch.seqs # seq in one-hot format\n",
    "    int_seqs = batch.int_seqs # seq in int format\n",
    "    masks = batch.msks # which positions are valid\n",
    "    lengths = batch.lengths # seq length\n",
    "    evos = batch.evos # PSSM / evolutionary info\n",
    "    angs = batch.angs[:,:,0:2] # torsion angles: phi, psi\n",
    "    \n",
    "    # use coords to create distance matrix from c-beta\n",
    "    # except use c-alpha for G\n",
    "    # coords[:, 4, :] is c-beta, and coords[:, 1, :] is c-alpha\n",
    "    coords = batch.crds # seq coord info (all-atom)\n",
    "    batch_xyz = []\n",
    "    for i in range(coords.shape[0]):\n",
    "        xyz = []\n",
    "        xyz = [coords[i][cpos+4,:] \n",
    "                if masks[i][cpos//14] and str_seqs[i][cpos//14] != 'G'\n",
    "                else coords[i][cpos+1,:]\n",
    "                for cpos in range(0, coords[i].shape[0]-1, 14)]\n",
    "        batch_xyz.append(torch.stack(xyz))\n",
    "    batch_xyz = torch.stack(batch_xyz)\n",
    "    # now create pairwise distance matrix\n",
    "    dmats = torch.cdist(batch_xyz, batch_xyz)\n",
    "    # create matrix mask (0 means i,j invalid)\n",
    "    dmat_masks = torch.einsum('bi,bj->bij', masks, masks)\n",
    "    \n",
    "    return seqs, evos, angs, masks, dmats, dmat_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6969eac3-0163-479e-bc59-ae546aa2d338",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionHead(nn.Module):\n",
    "    '''\n",
    "    An Attenton head for row/column attention\n",
    "    '''\n",
    "    def __init__(self, num_heads, c, c_z, c_m):\n",
    "        super(AttentionHead, self).__init__()\n",
    "        \n",
    "        self.num_heads = num_heads\n",
    "        self.c = c\n",
    "        self.c_z = c_z\n",
    "        \n",
    "        #query key value\n",
    "        self.q = nn.Linear(c_m, self.c, bias = False)\n",
    "        self.k = nn.Linear(c_m, self.c, bias = False)\n",
    "        self.v = nn.Linear(c_m, self.c, bias = False)\n",
    "        \n",
    "        #bias projects z from 128 to 1\n",
    "        self.bias = nn.Linear(self.c_z, 1, bias = False)\n",
    "        \n",
    "    def forward(self, msa_rep, pair_rep, row):\n",
    "        #get query key value\n",
    "        query = self.q(msa_rep)\n",
    "        key = self.k(msa_rep)\n",
    "        value = self.v(msa_rep)\n",
    "        \n",
    "        out = torch.matmul(query,torch.transpose(key,1,2))/np.sqrt(self.c)\n",
    "        if row: \n",
    "            b = self.bias(pair_rep).squeeze()\n",
    "            out += b\n",
    "        \n",
    "        #softmax with respect to rows\n",
    "        out = F.softmax(out, dim = 1)\n",
    "        out = torch.matmul(out, value)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3fd7ddac-b3c4-4539-b0ce-8a46314de992",
   "metadata": {},
   "outputs": [],
   "source": [
    "class rowColAtt(nn.Module):\n",
    "    '''\n",
    "    Compute the row or column attention given c, c_m, c_z, num_heads, row, and device.\n",
    "    '''\n",
    "    def __init__(self, c, c_m, c_z, num_heads, row, device):\n",
    "        super(rowColAtt, self).__init__()\n",
    "        \n",
    "        self.row = row\n",
    "        self.num_heads = num_heads\n",
    "        self.device = device\n",
    "        \n",
    "        #attention heads\n",
    "        self.mhsa = nn.ModuleList([AttentionHead(num_heads, c, c_z, c_m) for i in range(self.num_heads)])\n",
    "        \n",
    "        #project to c_msa\n",
    "        self.fc1 = nn.Linear(c_z, c_m)\n",
    "        \n",
    "        self.gate = nn.ModuleList([nn.Sequential(nn.Linear(c_m, 1), nn.Sigmoid()) for i in range(self.num_heads)])\n",
    "        \n",
    "    def forward(self, msa_rep, pair_rep):\n",
    "        new_msa_rep = torch.empty(msa_rep.shape).to(self.device)\n",
    "        for s in range(msa_rep.shape[1]):\n",
    "            s_o = []\n",
    "            for i, head in enumerate(self.mhsa):\n",
    "                out = head(msa_rep[:,s,:,:], pair_rep, self.row)\n",
    "                gate = self.gate[i](msa_rep).squeeze(dim=-1)\n",
    "                final = torch.transpose(gate, 1, 2) * out       #gate is b x n_clust x n_res, out is b x n_res x c, cannot be dotted, might skew results\\n\",\n",
    "                s_o.append(final)\n",
    "                \n",
    "            new_slice = torch.concat(s_o, dim = 2)\n",
    "            new_slice = self.fc1(new_slice)\n",
    "            new_msa_rep[:,s,:,:] = new_slice\n",
    "            \n",
    "        return new_msa_rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "54e4847d-665b-48b7-b762-30e7a379d46c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Outer_Prod_Mean(nn.Module):\n",
    "    '''\n",
    "    Finds the outer product mean between the pair-wise representation\n",
    "    and the msa representation.\n",
    "    The output is a n_res x n_res x 128 pair_rep\n",
    "    '''\n",
    "    def __init__(self, c, c_m, c_z, device):\n",
    "        super(Outer_Prod_Mean, self).__init__()\n",
    "        self.device = device\n",
    "        \n",
    "        #linear layer to project i[s] and j[s] to c dim\n",
    "        self.fc1 = nn.Linear(c_m, c)\n",
    "        self.fc2 = nn.Linear(c_m, c)\n",
    "        \n",
    "        #flatten the mean outer product to C*C\n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        #linear layer to project the outer product mean to 128 dim\n",
    "        self.fc3 = nn.Linear(16, c_z)\n",
    "        \n",
    "        \n",
    "    def forward(self, msa_rep, pair_rep):\n",
    "        \n",
    "        #project m to A and B\n",
    "        new_pair_rep = torch.empty(pair_rep.shape).to(self.device)\n",
    "        \n",
    "        for i in range(msa_rep.shape[1]):\n",
    "            for j in range(msa_rep.shape[1]):\n",
    "                a = self.fc1(msa_rep[:,i,:,:])\n",
    "                b = self.fc2(msa_rep[:,j,:,:])\n",
    "                outer =torch.einsum('bij,bik->bijk',a,b)\n",
    "                out_mean = torch.mean(outer, dim = 1)\n",
    "                out = self.flatten(out_mean)\n",
    "                out = self.fc3(out)\n",
    "                new_pair_rep[:,i,j,:] = out\n",
    "\n",
    "        return new_pair_rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d02c25d7-afaa-4f00-a41f-e22aa3479522",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Mult_Attention(nn.Module):\n",
    "    def __init__(self, c_z, c_m, out, device):\n",
    "        '''\n",
    "        Does incoming(default) multiplicative attention on a given pair_rep.\n",
    "        out: set to False to do incoming attention\n",
    "        '''\n",
    "        super(Mult_Attention, self).__init__()\n",
    "        self.device = device\n",
    "        self.out = out\n",
    "        self.ln = nn.LayerNorm(c_z)\n",
    "        self.fc1 = nn.Linear(c_z, c_z)\n",
    "        self.fc2 = nn.Linear(c_z, c_z)\n",
    "        self.fc3 = nn.Linear(c_m, c_z)\n",
    "\n",
    "        self.gate1 = nn.Sequential(nn.Linear(c_z, c_z), nn.Sigmoid())\n",
    "        self.gate2 = nn.Sequential(nn.Linear(c_z, c_z), nn.Sigmoid())\n",
    "        self.gate3 = nn.Sequential(nn.Linear(c_z, c_m), nn.Sigmoid())\n",
    "\n",
    "    def forward(self, pair_rep):\n",
    "        #Do a layer norm on pair_rep\n",
    "        pair_rep = self.ln(pair_rep)\n",
    "        Z = torch.zeros((pair_rep.shape[0], pair_rep.shape[1], pair_rep.shape[2], c_m)).to(self.device)\n",
    "        #make A and B\n",
    "        A = self.fc1(pair_rep)\n",
    "        B = self.fc2(pair_rep)\n",
    "\n",
    "        #Make gates for A and B\n",
    "        gate_A = self.gate1(pair_rep)\n",
    "        gate_B = self.gate2(pair_rep)\n",
    "        gate_Z = self.gate3(pair_rep)\n",
    "\n",
    "        #take dot product of A, B and their gates\n",
    "        new_A = A * gate_A\n",
    "        new_B = B * gate_B\n",
    "\n",
    "        #transpose a and b if we are doing incoming attention\n",
    "        if not self.out:\n",
    "            new_A = torch.transpose(new_A, 1, 2)\n",
    "            new_B = torch.transpose(new_B, 1, 2)\n",
    "\n",
    "        for i in range(new_A.shape[1]):\n",
    "            for j in range(new_B.shape[2]):\n",
    "                Z[:,i,j] = gate_Z[:,i,j] * (torch.sum((new_A[:,i,:] * new_B[:,j,:]), dim = -1))\n",
    "\n",
    "        return self.fc3(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fd194cd3-79af-4562-b175-a5231d924968",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tri_Attention(nn.Module):\n",
    "    '''\n",
    "    Does starting triangular attention by default.\n",
    "    ending: set to true to do ending triangular attention\n",
    "    '''\n",
    "    def __init__(self, c, c_z, ending = False, num_heads = 4):\n",
    "        super(Tri_Attention, self).__init__()\n",
    "        self.ending = ending\n",
    "        self.num_heads = num_heads\n",
    "        self.c = c\n",
    "        \n",
    "        self.q = nn.ModuleList([nn.Linear(c_z, c) for i in range(num_heads)])\n",
    "        self.k = nn.ModuleList([nn.Linear(c_z, c) for i in range(num_heads)])\n",
    "        self.v = nn.ModuleList([nn.Linear(c_z, c) for i in range(num_heads)])\n",
    "        self.b = nn.ModuleList([nn.Linear(c_z, 1) for i in range(num_heads)])\n",
    "        self.g = nn.ModuleList([nn.Sequential(nn.Linear(c_z,c), nn.Sigmoid()) for i in range(num_heads)])\n",
    "        \n",
    "        self.fc1 = nn.Linear(16, c_z)\n",
    "        \n",
    "    def forward(self, pair_rep):\n",
    "        output = []\n",
    "        for h in range(self.num_heads):\n",
    "            query = self.q[h](pair_rep)\n",
    "            key = self.k[h](pair_rep)\n",
    "            value = self.v[h](pair_rep)\n",
    "            bias = self.b[h](pair_rep)\n",
    "            gate = self.g[h](pair_rep)\n",
    "            \n",
    "            #find attention\n",
    "            a = (query * key)/np.sqrt(self.c) + bias\n",
    "            a = F.softmax(a, dim = -1)\n",
    "            a = a * value\n",
    "            out = a * gate\n",
    "            output.append(out)\n",
    "        \n",
    "        #concat all outputs\n",
    "        output = torch.concat(output, -1)\n",
    "        output = self.fc1(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6df0f741-c8fc-4e5e-858b-6a635e630516",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evoformer(nn.Module):\n",
    "    def __init__(self, c, c_m, c_z, n_clust, num_heads, device):\n",
    "        '''\n",
    "        Implements the main evoformer trunk.\n",
    "        c = number of clusters\n",
    "        c_m = msa_rep dim\n",
    "        c_z = pair_rep dim\n",
    "        n_clust: number of PSSMs.\n",
    "        num_heads: number of attention heads(8 by default)\n",
    "        '''\n",
    "        super(Evoformer, self).__init__()\n",
    "        \n",
    "        self.n_clust = n_clust\n",
    "        self.num_heads = num_heads\n",
    "        self.device = device\n",
    "        \n",
    "        #linear layers to project evos into n_clust x n_res x c_m\n",
    "        self.fc0 = nn.ModuleList([nn.Linear(21, c_m) for i in range(n_clust)])\n",
    "        #linear layer to project seqs to n_res x c_m\n",
    "        self.fc1 = nn.Linear(20, c_m)\n",
    "        #linear layer to project seqs to n_res x c_z\n",
    "        self.fc2 = nn.Linear(20, c_z)\n",
    "        self.fc3 = nn.Linear(20, c_z)\n",
    "        #Linear layer to project distances into c_z\n",
    "        self.fc4 = nn.Linear(64, c_z)\n",
    "        #linear layer to project pair_rep to bias\n",
    "        self.fc5 = nn.Linear(c_z, 1)\n",
    "        #linear layer to project the single representation to c_m\n",
    "        self.fc6 = nn.Linear(c_m, c_m)\n",
    "        #linear layer to project the single representation to 384 dim\n",
    "        self.fc7 = nn.Linear(c_m, 384)\n",
    "        \n",
    "        #define the transitional layers to pass the new msa_rep through\n",
    "        self.transition1 = nn.Sequential(nn.Linear(c_m, 4*c_m), nn.ReLU(), nn.Linear(4*c_m, c_m))\n",
    "        self.transition2 = nn.Sequential(nn.Linear(c_z, 4*c_z), nn.ReLU(), nn.Linear(4*c_z, c_z))\n",
    "        \n",
    "        #define all attentions\n",
    "        self.row_att = rowColAtt(c, c_m, c_z, self.num_heads, True, self.device)\n",
    "        self.col_att = rowColAtt(c, c_m, c_z, self.num_heads, False, self.device)\n",
    "        self.mul_att_in = Mult_Attention(c_z, c_m, False, device)\n",
    "        self.mul_att_out = Mult_Attention(c_z, c_m, True, device)\n",
    "        self.tri_att_start = Tri_Attention(c, c_z, ending = False)\n",
    "        self.tri_att_end = Tri_Attention(c, c_z, ending = True)\n",
    "        \n",
    "        #define outer_product_mean\n",
    "        self.out_prod_mean = Outer_Prod_Mean(c, c_m, c_z, self.device)\n",
    "        \n",
    "    \n",
    "    def create_msa_rep(self, evos, seqs):\n",
    "        '''\n",
    "        Create the msa_representation given evolutionary data evos\n",
    "        and the seqs, both are n_res x 21.\n",
    "        '''\n",
    "        #obtain n_clust layers of PSSM(evos); stack them into a (n_clust x n_res x 256) matrix\n",
    "        clusters = [self.fc0[i](evos) for i in range(self.n_clust)]\n",
    "        msa_rep = torch.stack(clusters, dim=1)\n",
    "        \n",
    "        #project the seqs from n_res x 21 to n_res x 256 and tile it.\n",
    "        new_seqs = self.fc1(seqs)\n",
    "        new_seqs = new_seqs.unsqueeze(dim=1)\n",
    "        new_seqs = torch.tile(new_seqs, (1, self.n_clust, 1, 1))\n",
    "        \n",
    "        #add the seqs to the msa_rep\n",
    "        msa_rep += new_seqs\n",
    "        \n",
    "        return msa_rep\n",
    "    \n",
    "    def create_pair_rep(self, seqs):\n",
    "        '''\n",
    "        Create pair_wise representations given seqs.\n",
    "        '''\n",
    "        #create the pairwise rep matrix\n",
    "        a_i = self.fc2(seqs).unsqueeze(dim=2)\n",
    "        b_j = self.fc3(seqs).unsqueeze(dim=2)\n",
    "        a_i = torch.tile(a_i, (1, 1, a_i.shape[1], 1))\n",
    "        b_j = torch.tile(b_j, (1, 1, b_j.shape[1], 1))\n",
    "        pair_rep = a_i + torch.transpose(b_j, 1, 2)\n",
    "        \n",
    "        #add the relative position rel_pos\n",
    "        idx_j = torch.arange(0, seqs.shape[1]).unsqueeze(dim=1)\n",
    "        idx_j = torch.tile(idx_j, (1, idx_j.shape[1]))\n",
    "        idx_i = torch.transpose(idx_j, 0, 1)\n",
    "        # idx_i , idx_j = idx_i.to(device), idx_j.to(device)\n",
    "        dist_ij = idx_i - idx_j   \n",
    "        bins = torch.linspace(-32, 32, 64)\n",
    "        dist_ij = torch.bucketize(dist_ij, bins)\n",
    "        dist_ij[dist_ij>=64] = 63\n",
    "        dist_ij = dist_ij.unsqueeze(dim=0)\n",
    "        dist_ij = torch.tile(dist_ij, (pair_rep.shape[0], 1, 1))\n",
    "        dist_ij = F.one_hot(dist_ij).type(torch.float)\n",
    "        dist_ij = dist_ij.to(self.device)\n",
    "        rel_pos = self.fc4(dist_ij)\n",
    "        pair_rep += rel_pos\n",
    "        return pair_rep\n",
    "    \n",
    "    def create_bias(self, pair_rep):\n",
    "        '''\n",
    "        given the pairwise representation create the bias\n",
    "        '''\n",
    "        bias = self.fc5(pair_rep)\n",
    "        return bias\n",
    "        \n",
    "    def single_rep(self, msa_rep):\n",
    "        '''\n",
    "        Find the singular representation of M\n",
    "        Should only be done on the last block.\n",
    "        '''\n",
    "        single_rep = self.fc6(msa_rep[:,1,:,:])\n",
    "        single_rep = self.fc7(single_rep)\n",
    "        return single_rep  \n",
    "    \n",
    "    def forward(self, seqs, evos):\n",
    "        #create msa_rep, pair_rep, bias\n",
    "        msa_rep = self.create_msa_rep(evos, seqs)\n",
    "        pair_rep = self.create_pair_rep(seqs)\n",
    "        # bias = self.create_bias(pair_rep)\n",
    "        \n",
    "        # #feed msa_rep into row -> col -> transition\n",
    "        msa_rep = msa_rep + self.row_att(msa_rep, pair_rep) \n",
    "        msa_rep = msa_rep + self.col_att(msa_rep, pair_rep)\n",
    "        msa_rep = msa_rep + self.transition1(msa_rep) #output of evoformer for msa_rep\n",
    "        \n",
    "        #do the outer product mean\n",
    "        pair_rep = pair_rep + self.out_prod_mean(msa_rep, pair_rep)\n",
    "        \n",
    "        #do triangular attention\n",
    "        pair_rep = pair_rep + self.mul_att_out(pair_rep) \n",
    "        pair_rep = pair_rep + self.mul_att_in(pair_rep)\n",
    "        pair_rep = pair_rep + self.tri_att_start(pair_rep)\n",
    "        pair_rep = pair_rep + self.tri_att_end(pair_rep)\n",
    "        \n",
    "        #do the transition\n",
    "        pair_rep = pair_rep + self.transition2(pair_rep) #output of evoformer for pair_rep\n",
    "        \n",
    "        single_rep = self.single_rep(msa_rep)\n",
    "        return msa_rep, pair_rep, single_rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2f916c17-b347-4b83-988b-c593b1dc9dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvoformerBlock(nn.Module):\n",
    "    '''\n",
    "    A wrapper for the evoformer trunk to support multi-block training.\n",
    "    Also convolutes the pair_rep into pred_dmat and pred_angles.\n",
    "    '''\n",
    "    def __init__(self, c, c_m, c_z, num_blocks, n_clust, num_heads, device):\n",
    "        super(EvoformerBlock, self).__init__()\n",
    "        \n",
    "        self.num_blocks = num_blocks\n",
    "        self.evo_blocks = nn.ModuleList([Evoformer(c, c_m, c_z, n_clust, num_heads, device) for i in range(num_blocks)])\n",
    "        \n",
    "        #dmat\n",
    "        self.conv1 = nn.Conv2d(c_z, 64, 1)\n",
    "        \n",
    "        #angle \n",
    "        self.maxpool = nn.MaxPool2d((1,c_m))\n",
    "        self.conv2 = nn.Conv2d(c_z, 1296, 1)\n",
    "        \n",
    "    def forward(self, seqs, evos):\n",
    "        output = self.evo_blocks[0](seqs, evos)\n",
    "        \n",
    "        #single rep is calculated but ignored until the last output\n",
    "        for i in range(1, self.num_blocks):\n",
    "            output = self.evo_blocks[0](output[0], output[1])\n",
    "        \n",
    "        #do convolutions to obtain the angle prediction\n",
    "        pred_dmat = self.conv1(torch.transpose(output[1], 1, 3))\n",
    "        \n",
    "        #obtain the angle predictions by maxpooling\n",
    "        pred_angles = self.maxpool(torch.transpose(output[1], 1, 3))  #shapes are b x cm x cm x c\n",
    "        pred_angles = self.conv2(pred_angles)\n",
    "        # print(pred_dmat)\n",
    "        \n",
    "        return pred_dmat, pred_angles, output[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b33c7b74-6d7b-4367-8086-e5398fc856db",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EvoformerBlock(\n",
       "  (evo_blocks): ModuleList(\n",
       "    (0): Evoformer(\n",
       "      (fc0): ModuleList(\n",
       "        (0): Linear(in_features=21, out_features=64, bias=True)\n",
       "        (1): Linear(in_features=21, out_features=64, bias=True)\n",
       "        (2): Linear(in_features=21, out_features=64, bias=True)\n",
       "        (3): Linear(in_features=21, out_features=64, bias=True)\n",
       "      )\n",
       "      (fc1): Linear(in_features=20, out_features=64, bias=True)\n",
       "      (fc2): Linear(in_features=20, out_features=16, bias=True)\n",
       "      (fc3): Linear(in_features=20, out_features=16, bias=True)\n",
       "      (fc4): Linear(in_features=64, out_features=16, bias=True)\n",
       "      (fc5): Linear(in_features=16, out_features=1, bias=True)\n",
       "      (fc6): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (fc7): Linear(in_features=64, out_features=384, bias=True)\n",
       "      (transition1): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=256, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=256, out_features=64, bias=True)\n",
       "      )\n",
       "      (transition2): Sequential(\n",
       "        (0): Linear(in_features=16, out_features=64, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=64, out_features=16, bias=True)\n",
       "      )\n",
       "      (row_att): rowColAtt(\n",
       "        (mhsa): ModuleList(\n",
       "          (0): AttentionHead(\n",
       "            (q): Linear(in_features=64, out_features=4, bias=False)\n",
       "            (k): Linear(in_features=64, out_features=4, bias=False)\n",
       "            (v): Linear(in_features=64, out_features=4, bias=False)\n",
       "            (bias): Linear(in_features=16, out_features=1, bias=False)\n",
       "          )\n",
       "          (1): AttentionHead(\n",
       "            (q): Linear(in_features=64, out_features=4, bias=False)\n",
       "            (k): Linear(in_features=64, out_features=4, bias=False)\n",
       "            (v): Linear(in_features=64, out_features=4, bias=False)\n",
       "            (bias): Linear(in_features=16, out_features=1, bias=False)\n",
       "          )\n",
       "          (2): AttentionHead(\n",
       "            (q): Linear(in_features=64, out_features=4, bias=False)\n",
       "            (k): Linear(in_features=64, out_features=4, bias=False)\n",
       "            (v): Linear(in_features=64, out_features=4, bias=False)\n",
       "            (bias): Linear(in_features=16, out_features=1, bias=False)\n",
       "          )\n",
       "          (3): AttentionHead(\n",
       "            (q): Linear(in_features=64, out_features=4, bias=False)\n",
       "            (k): Linear(in_features=64, out_features=4, bias=False)\n",
       "            (v): Linear(in_features=64, out_features=4, bias=False)\n",
       "            (bias): Linear(in_features=16, out_features=1, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (fc1): Linear(in_features=16, out_features=64, bias=True)\n",
       "        (gate): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Linear(in_features=64, out_features=1, bias=True)\n",
       "            (1): Sigmoid()\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Linear(in_features=64, out_features=1, bias=True)\n",
       "            (1): Sigmoid()\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): Linear(in_features=64, out_features=1, bias=True)\n",
       "            (1): Sigmoid()\n",
       "          )\n",
       "          (3): Sequential(\n",
       "            (0): Linear(in_features=64, out_features=1, bias=True)\n",
       "            (1): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (col_att): rowColAtt(\n",
       "        (mhsa): ModuleList(\n",
       "          (0): AttentionHead(\n",
       "            (q): Linear(in_features=64, out_features=4, bias=False)\n",
       "            (k): Linear(in_features=64, out_features=4, bias=False)\n",
       "            (v): Linear(in_features=64, out_features=4, bias=False)\n",
       "            (bias): Linear(in_features=16, out_features=1, bias=False)\n",
       "          )\n",
       "          (1): AttentionHead(\n",
       "            (q): Linear(in_features=64, out_features=4, bias=False)\n",
       "            (k): Linear(in_features=64, out_features=4, bias=False)\n",
       "            (v): Linear(in_features=64, out_features=4, bias=False)\n",
       "            (bias): Linear(in_features=16, out_features=1, bias=False)\n",
       "          )\n",
       "          (2): AttentionHead(\n",
       "            (q): Linear(in_features=64, out_features=4, bias=False)\n",
       "            (k): Linear(in_features=64, out_features=4, bias=False)\n",
       "            (v): Linear(in_features=64, out_features=4, bias=False)\n",
       "            (bias): Linear(in_features=16, out_features=1, bias=False)\n",
       "          )\n",
       "          (3): AttentionHead(\n",
       "            (q): Linear(in_features=64, out_features=4, bias=False)\n",
       "            (k): Linear(in_features=64, out_features=4, bias=False)\n",
       "            (v): Linear(in_features=64, out_features=4, bias=False)\n",
       "            (bias): Linear(in_features=16, out_features=1, bias=False)\n",
       "          )\n",
       "        )\n",
       "        (fc1): Linear(in_features=16, out_features=64, bias=True)\n",
       "        (gate): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Linear(in_features=64, out_features=1, bias=True)\n",
       "            (1): Sigmoid()\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Linear(in_features=64, out_features=1, bias=True)\n",
       "            (1): Sigmoid()\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): Linear(in_features=64, out_features=1, bias=True)\n",
       "            (1): Sigmoid()\n",
       "          )\n",
       "          (3): Sequential(\n",
       "            (0): Linear(in_features=64, out_features=1, bias=True)\n",
       "            (1): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (mul_att_in): Mult_Attention(\n",
       "        (ln): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (fc3): Linear(in_features=64, out_features=16, bias=True)\n",
       "        (gate1): Sequential(\n",
       "          (0): Linear(in_features=16, out_features=16, bias=True)\n",
       "          (1): Sigmoid()\n",
       "        )\n",
       "        (gate2): Sequential(\n",
       "          (0): Linear(in_features=16, out_features=16, bias=True)\n",
       "          (1): Sigmoid()\n",
       "        )\n",
       "        (gate3): Sequential(\n",
       "          (0): Linear(in_features=16, out_features=64, bias=True)\n",
       "          (1): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (mul_att_out): Mult_Attention(\n",
       "        (ln): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "        (fc1): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (fc2): Linear(in_features=16, out_features=16, bias=True)\n",
       "        (fc3): Linear(in_features=64, out_features=16, bias=True)\n",
       "        (gate1): Sequential(\n",
       "          (0): Linear(in_features=16, out_features=16, bias=True)\n",
       "          (1): Sigmoid()\n",
       "        )\n",
       "        (gate2): Sequential(\n",
       "          (0): Linear(in_features=16, out_features=16, bias=True)\n",
       "          (1): Sigmoid()\n",
       "        )\n",
       "        (gate3): Sequential(\n",
       "          (0): Linear(in_features=16, out_features=64, bias=True)\n",
       "          (1): Sigmoid()\n",
       "        )\n",
       "      )\n",
       "      (tri_att_start): Tri_Attention(\n",
       "        (q): ModuleList(\n",
       "          (0): Linear(in_features=16, out_features=4, bias=True)\n",
       "          (1): Linear(in_features=16, out_features=4, bias=True)\n",
       "          (2): Linear(in_features=16, out_features=4, bias=True)\n",
       "          (3): Linear(in_features=16, out_features=4, bias=True)\n",
       "        )\n",
       "        (k): ModuleList(\n",
       "          (0): Linear(in_features=16, out_features=4, bias=True)\n",
       "          (1): Linear(in_features=16, out_features=4, bias=True)\n",
       "          (2): Linear(in_features=16, out_features=4, bias=True)\n",
       "          (3): Linear(in_features=16, out_features=4, bias=True)\n",
       "        )\n",
       "        (v): ModuleList(\n",
       "          (0): Linear(in_features=16, out_features=4, bias=True)\n",
       "          (1): Linear(in_features=16, out_features=4, bias=True)\n",
       "          (2): Linear(in_features=16, out_features=4, bias=True)\n",
       "          (3): Linear(in_features=16, out_features=4, bias=True)\n",
       "        )\n",
       "        (b): ModuleList(\n",
       "          (0): Linear(in_features=16, out_features=1, bias=True)\n",
       "          (1): Linear(in_features=16, out_features=1, bias=True)\n",
       "          (2): Linear(in_features=16, out_features=1, bias=True)\n",
       "          (3): Linear(in_features=16, out_features=1, bias=True)\n",
       "        )\n",
       "        (g): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Linear(in_features=16, out_features=4, bias=True)\n",
       "            (1): Sigmoid()\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Linear(in_features=16, out_features=4, bias=True)\n",
       "            (1): Sigmoid()\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): Linear(in_features=16, out_features=4, bias=True)\n",
       "            (1): Sigmoid()\n",
       "          )\n",
       "          (3): Sequential(\n",
       "            (0): Linear(in_features=16, out_features=4, bias=True)\n",
       "            (1): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (fc1): Linear(in_features=16, out_features=16, bias=True)\n",
       "      )\n",
       "      (tri_att_end): Tri_Attention(\n",
       "        (q): ModuleList(\n",
       "          (0): Linear(in_features=16, out_features=4, bias=True)\n",
       "          (1): Linear(in_features=16, out_features=4, bias=True)\n",
       "          (2): Linear(in_features=16, out_features=4, bias=True)\n",
       "          (3): Linear(in_features=16, out_features=4, bias=True)\n",
       "        )\n",
       "        (k): ModuleList(\n",
       "          (0): Linear(in_features=16, out_features=4, bias=True)\n",
       "          (1): Linear(in_features=16, out_features=4, bias=True)\n",
       "          (2): Linear(in_features=16, out_features=4, bias=True)\n",
       "          (3): Linear(in_features=16, out_features=4, bias=True)\n",
       "        )\n",
       "        (v): ModuleList(\n",
       "          (0): Linear(in_features=16, out_features=4, bias=True)\n",
       "          (1): Linear(in_features=16, out_features=4, bias=True)\n",
       "          (2): Linear(in_features=16, out_features=4, bias=True)\n",
       "          (3): Linear(in_features=16, out_features=4, bias=True)\n",
       "        )\n",
       "        (b): ModuleList(\n",
       "          (0): Linear(in_features=16, out_features=1, bias=True)\n",
       "          (1): Linear(in_features=16, out_features=1, bias=True)\n",
       "          (2): Linear(in_features=16, out_features=1, bias=True)\n",
       "          (3): Linear(in_features=16, out_features=1, bias=True)\n",
       "        )\n",
       "        (g): ModuleList(\n",
       "          (0): Sequential(\n",
       "            (0): Linear(in_features=16, out_features=4, bias=True)\n",
       "            (1): Sigmoid()\n",
       "          )\n",
       "          (1): Sequential(\n",
       "            (0): Linear(in_features=16, out_features=4, bias=True)\n",
       "            (1): Sigmoid()\n",
       "          )\n",
       "          (2): Sequential(\n",
       "            (0): Linear(in_features=16, out_features=4, bias=True)\n",
       "            (1): Sigmoid()\n",
       "          )\n",
       "          (3): Sequential(\n",
       "            (0): Linear(in_features=16, out_features=4, bias=True)\n",
       "            (1): Sigmoid()\n",
       "          )\n",
       "        )\n",
       "        (fc1): Linear(in_features=16, out_features=16, bias=True)\n",
       "      )\n",
       "      (out_prod_mean): Outer_Prod_Mean(\n",
       "        (fc1): Linear(in_features=64, out_features=4, bias=True)\n",
       "        (fc2): Linear(in_features=64, out_features=4, bias=True)\n",
       "        (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "        (fc3): Linear(in_features=16, out_features=16, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (conv1): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (maxpool): MaxPool2d(kernel_size=(1, 64), stride=(1, 64), padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(16, 1296, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = f'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"using device: {device}\")\n",
    "\n",
    "epochs = 1\n",
    "learning_rate = 0.00001\n",
    "\n",
    "num_heads = 4\n",
    "n_clust = 4\n",
    "num_blocks = 1\n",
    "c = 4\n",
    "c_m = 64\n",
    "c_z = 16\n",
    "c_s = 64\n",
    "\n",
    "model = EvoformerBlock(c, c_m, c_z, num_blocks, n_clust, num_heads, device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "model = model.to(device)\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a78894-7d51-4726-99b0-521cec455498",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1011 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "loss_func = nn.CrossEntropyLoss(reduction = 'none')\n",
    "for epoch in range(1,epochs+1):\n",
    "    training_loss = 0.\n",
    "    num_crops = 0\n",
    "    for bidx, (batch) in enumerate(tqdm(data['train'])):\n",
    "        seqs, evos, angs, masks, dmats, dmat_masks = get_seq_features(batch)\n",
    "        seqs, evos, angs, masks, dmats, dmat_masks = seqs.to(device), evos.to(device), angs.to(device), masks.to(device), dmats.to(device), dmat_masks.to(device)\n",
    "        \n",
    "        #generate a random starting index\n",
    "        start_idx = random.randint(1,16)\n",
    "        \n",
    "        original_shape = seqs.shape\n",
    "        seqs = F.pad(seqs, (0, 0, 0, seqs.shape[1] + c_s), 'constant', 0)\n",
    "        evos = F.pad(evos, (0, 0, 0, evos.shape[1] + c_s), 'constant', 0)\n",
    "        \n",
    "        #discretize the matrix\n",
    "        bins = torch.linspace(2,22, 64)\n",
    "        bins = bins.to(device)\n",
    "        discretized = torch.clamp(dmats, min = 2, max = 22)\n",
    "        discretized = torch.bucketize(discretized, bins, right = False)\n",
    "        discretized = F.pad(discretized, (0, discretized.shape[1] + c_s, 0, discretized.shape[1] + c_s, 0, 0), 'constant', 0)\n",
    "        pad_mask = F.pad(dmat_masks, (0, dmat_masks.shape[1] + c_s, 0, dmat_masks.shape[1] + c_s, 0, 0), 'constant', 0)\n",
    "\n",
    "        #discretize the angles\n",
    "        bins = torch.linspace(0, 36, 1296)\n",
    "        bins = bins.to(device)\n",
    "        d_angs = torch.clamp(angs, min = 0 , max = 36)\n",
    "        d_angs = d_angs.to(device)\n",
    "        d_angs = torch.bucketize(d_angs, bins, right = True)\n",
    "        d_angs = 36 * d_angs[:,:,0] + d_angs[:,:,1]\n",
    "        d_angs = F.pad(d_angs, (0, d_angs.shape[1] + c_s, 0, 0), 'constant', 0)\n",
    "        \n",
    "        for i in range(start_idx, original_shape[1], 64):\n",
    "            seq_crop = seqs[:,i:i+c_s,:]\n",
    "            evo_crop = evos[:,i:i+c_s,:]\n",
    "            ddmat = discretized[:,i:i+c_s, i:i+c_s]\n",
    "            new_angs = d_angs[:,i:i+c_s]\n",
    "            mask = pad_mask[:,i:i+c_s, i:i+c_s]\n",
    "            \n",
    "            #zero out previous gradients\n",
    "            model.zero_grad()\n",
    "            \n",
    "            #forward pass\n",
    "            dmat_pred, ang_pred, single_rep = model(seq_crop.type(torch.float), evo_crop)\n",
    "            #calculate loss\n",
    "            dmat_loss = loss_func(dmat_pred, ddmat.long())\n",
    " \n",
    "            #angs_loss = loss_func(ang_pred.squeeze(dim=-1), new_angs.long())\n",
    "            loss = torch.mean(dmat_loss*mask) #+ torch.mean(angs_loss)\n",
    "        \n",
    "            if(torch.isnan(loss)): continue\n",
    "            training_loss += loss.item()\n",
    "            num_crops += 1\n",
    "            \n",
    "            #backpropagate and step\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        if bidx % 100 == 0:\n",
    "            checkpoint = {\n",
    "                'batch': bidx,\n",
    "                'epoch': epoch,\n",
    "                'loss': training_loss,\n",
    "                'state_dict': model.state_dict(),\n",
    "                'optimizer': optimizer.state_dict()\n",
    "            }\n",
    "            torch.save(checkpoint, \"alphafold2.pth\")\n",
    "    training_loss /= num_crops\n",
    "    with open('output.txt', 'a') as fp:\n",
    "        fp.write(f\"Epoch: {epoch} Loss: {training_loss}\\n\")\n",
    "        print(f\"Epoch: {epoch} Loss: {training_loss}\")\n",
    "    fp.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "066d66ef-b601-4c5c-bd14-b877a159c74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Model from parameters\n",
    "saveinfo = torch.load(\"alphafold2.pth\")\n",
    "model.load_state_dict(saveinfo['state_dict'])\n",
    "optimizer.load_state_dict(saveinfo['optimizer'])\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6e042169-e4e3-45a8-b464-407882b56404",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_accs(accs_arr, L):\n",
    "    '''\n",
    "    given an array of accuracies print the accuracy of the top L, L/2, and L/5 accuracies.\n",
    "    '''\n",
    "    #sort the array in descending order\n",
    "    accs_arr.sort(reverse = True)\n",
    "    accs_arr = torch.Tensor(accs_arr)\n",
    "    arr_len = accs_arr.shape[0]\n",
    "    \n",
    "    #Find the denominator for each section\n",
    "    denom_long = min(L, arr_len)\n",
    "    denom_med = min(L/2, arr_len)\n",
    "    denom_short = min(L/5, arr_len)\n",
    "    \n",
    "    long_acc = torch.sum(accs_arr[:L])/denom_long\n",
    "    med_acc = torch.sum(accs_arr[:L//2])/denom_med\n",
    "    short_acc = torch.sum(accs_arr[:L//5])/denom_short\n",
    "    \n",
    "    print(f\"Top L Accuracy: {long_acc:.6f}\")\n",
    "    print(f\"Top L/2 Accuracy: {med_acc:.6f}\")\n",
    "    print(f\"Top L/5 Accuracy: {short_acc:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7b64323e-11e3-47cb-8a3d-f25a73e5709e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:01<00:10,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 0, Running Loss: 3.53185727, Running Length: 1748588, Loss Per Position: 0.00000202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [00:02<00:09,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 1, Running Loss: 4.09837317, Running Length: 2538862, Loss Per Position: 0.00000161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [00:03<00:08,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 2, Running Loss: 5.78084683, Running Length: 3503330, Loss Per Position: 0.00000165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [00:05<00:08,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 3, Running Loss: 7.00886616, Running Length: 3973282, Loss Per Position: 0.00000176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [00:07<00:07,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 4, Running Loss: 8.28406185, Running Length: 4539542, Loss Per Position: 0.00000182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [00:09<00:07,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 5, Running Loss: 10.81189206, Running Length: 5578012, Loss Per Position: 0.00000194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [00:12<00:07,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 6, Running Loss: 13.08866299, Running Length: 7114670, Loss Per Position: 0.00000184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [00:16<00:05,  2.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 7, Running Loss: 14.21622843, Running Length: 8255828, Loss Per Position: 0.00000172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [00:21<00:03,  3.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 8, Running Loss: 18.71532175, Running Length: 10577740, Loss Per Position: 0.00000177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:27<00:00,  2.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 9, Running Loss: 24.87288906, Running Length: 4411578, Loss Per Position: 0.00000564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "short_acc = []\n",
    "med_acc = []\n",
    "long_acc = []\n",
    "total_acc = []\n",
    "with torch.no_grad():\n",
    "    for bidx, batch in tqdm(enumerate(data['test']), total=len(data['test'])):\n",
    "        running_loss = 0\n",
    "        running_len = 0\n",
    "        seqs, evos, angs, masks, dmats, dmat_masks = get_seq_features(batch)\n",
    "        seqs, evos, angs, masks, dmats, dmat_masks = seqs.to(device), evos.to(device), angs.to(device), masks.to(device), dmats.to(device), dmat_masks.to(device)\n",
    "\n",
    "        #generate a random starting index\n",
    "        start_idx = random.randint(1,16)\n",
    "\n",
    "        original_shape = seqs.shape\n",
    "        seqs = F.pad(seqs, (0, 0, 0, c_s), 'constant', 0)\n",
    "        evos = F.pad(evos, (0, 0, 0, c_s), 'constant', 0)\n",
    "\n",
    "        #discretize the matrix\n",
    "        bins = torch.linspace(2,22, 64)\n",
    "        bins = bins.to(device)\n",
    "        discretized = torch.clamp(dmats, min = 2, max = 22)\n",
    "        discretized = torch.bucketize(discretized, bins, right = False)\n",
    "        discretized = F.pad(discretized, (0, discretized.shape[1] + c_s, 0, discretized.shape[1] + c_s, 0, 0), 'constant', 0)\n",
    "        pad_mask = F.pad(dmat_masks, (0,  c_s, 0, c_s, 0, 0), 'constant', 0)\n",
    "        \n",
    "        #discretize the angles\n",
    "        bins = torch.linspace(0, 36, 1296)\n",
    "        bins = bins.to(device)\n",
    "        d_angs = torch.clamp(angs, min = 0 , max = 36)\n",
    "        d_angs = d_angs.to(device)\n",
    "        d_angs = torch.bucketize(d_angs, bins, right = True)\n",
    "        d_angs = 36 * d_angs[:,:,0] + d_angs[:,:,1]\n",
    "        d_angs = F.pad(d_angs, (0, d_angs.shape[1] + c_s, 0, 0), 'constant', 0)\n",
    "        \n",
    "        \n",
    "        contact_map = torch.zeros((discretized.shape[0], 64, discretized.shape[1], discretized.shape[2])).to(device)\n",
    "        contact_map_crops = torch.zeros((discretized.shape[0], 64, discretized.shape[1], discretized.shape[2])).to(device)\n",
    "        j_indicies = torch.arange(0,dmats.shape[1])\n",
    "        j_indicies = torch.tile(j_indicies, (dmats.shape[1], 1))\n",
    "        i_indicies = torch.transpose(j_indicies, 0, 1)    \n",
    "        \n",
    "        diff_indicies = torch.abs(i_indicies - j_indicies)\n",
    "        diff_indicies = diff_indicies.to(device)\n",
    "        \n",
    "        #copy all prediction crops and store in r_matr\n",
    "        r_matr = torch.zeros(discretized.shape[0], discretized.shape[1], discretized.shape[2])\n",
    "        r_matr = r_matr.to(device)\n",
    "        \n",
    "        for i in range(start_idx, original_shape[1], 64):\n",
    "            seq_crop = seqs[:,i:i+c_s,:]\n",
    "            evo_crop = evos[:,i:i+c_s,:]\n",
    "            ddmat = discretized[:,i:i+c_s, i:i+c_s]\n",
    "            new_angs = d_angs[:,i:i+c_s]\n",
    "            mask = pad_mask[:,i:i+c_s, i:i+c_s]\n",
    "\n",
    "            #forward pass\n",
    "            dmat_pred, ang_pred, single_rep = model(seq_crop.type(torch.float), evo_crop)\n",
    "            # print(dmat_pred.shape)\n",
    "            contact_map[:,:,i:i+64,i:i+64] += F.softmax(dmat_pred, dim=1)\n",
    "            contact_map_crops[:,:,i:i+64,i:i+64] += 1\n",
    "            #calculate loss\n",
    "\n",
    "            loss = F.cross_entropy(dmat_pred, ddmat, reduction='none')\n",
    "            loss = torch.mean(loss * mask)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            running_len += torch.sum(ddmat).item()\n",
    "            \n",
    "        contact_map_crops[contact_map_crops == 0] = 1\n",
    "        contact_map /= contact_map_crops\n",
    "        \n",
    "        #find positional matricies for short , med, and long\n",
    "        short_indicies = (diff_indicies >= 6) * (diff_indicies <= 11)\n",
    "        med_indicies = (diff_indicies >= 12) * (diff_indicies <= 23)\n",
    "        long_indicies = (diff_indicies >= 24)\n",
    "        \n",
    "        contact_map = contact_map[:,:,0:original_shape[1], 0:original_shape[1]]\n",
    "        discretized = discretized[:,0:original_shape[1], 0:original_shape[1]]\n",
    "        contact_map = torch.argmax(contact_map, dim=1)\n",
    "        discretized = discretized <= 19\n",
    "        contact_map = contact_map <= 19\n",
    "        \n",
    "        short_contact = contact_map * short_indicies\n",
    "        short_gt = discretized * short_indicies\n",
    "        med_contact = contact_map * med_indicies\n",
    "        med_gt = discretized * med_indicies\n",
    "        long_contact = contact_map * long_indicies\n",
    "        long_gt = discretized * long_indicies\n",
    "        short_acc.append(torch.sum(short_contact * discretized)/torch.sum(short_contact))\n",
    "        med_acc.append(torch.sum(med_contact * discretized)/torch.sum(med_contact))\n",
    "        long_acc.append(torch.sum(long_contact * discretized)/torch.sum(long_contact))\n",
    "        total_acc.append(torch.sum(contact_map * discretized)/torch.sum(contact_map))\n",
    "            \n",
    "        print(f\"batch: {bidx}, Running Loss: {running_loss:.8f}, Running Length: {running_len}, Loss Per Position: {running_loss/running_len:.8f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "33f5a2cd-19d6-414a-84bc-d67a1d244ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 24.87288906320464, Test Overall Accuracy: 0.047046\n",
      "Average Accuracy for Short: 0.100442\n",
      "Top L Accuracy: 0.100442\n",
      "Top L/2 Accuracy: 0.115556\n",
      "Top L/5 Accuracy: 0.162969\n",
      "Average Accuracy for Medium: 0.073326\n",
      "Top L Accuracy: 0.073326\n",
      "Top L/2 Accuracy: 0.084190\n",
      "Top L/5 Accuracy: 0.138045\n",
      "Average Accuracy for Long: 0.038819\n",
      "Top L Accuracy: 0.038819\n",
      "Top L/2 Accuracy: 0.045642\n",
      "Top L/5 Accuracy: 0.082133\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test Loss: {running_loss}, Test Overall Accuracy: {sum(total_acc)/len(total_acc):.6f}\")\n",
    "print(f\"Average Accuracy for Short: {sum(short_acc)/len(short_acc):.6f}\")\n",
    "print_accs(short_acc, 16)\n",
    "print(f\"Average Accuracy for Medium: {sum(med_acc)/len(med_acc):.6f}\")\n",
    "print_accs(med_acc, 16)\n",
    "print(f\"Average Accuracy for Long: {sum(long_acc)/len(long_acc):.6f}\")\n",
    "print_accs(long_acc, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fec335-1448-47c2-b4b3-6570bc537c79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "fd4ac733118b0a08e7ecfb18facc2f7ae7dbd4a959d020517c3646bcec335a14"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
